# python
prediction analysis
A false negative occurs if and only if the machine fails, and it is not a true positive.

A False Positive occurs if there is a failure signal, and a failure does not happen in the next 90 days. Also, if a signal occurs after the failure, this is a false positive.
A false negative occurs if and only if the machine fails, and it is not a true positive.

A False Positive occurs if there is a failure signal, and a failure does not happen in the next 90 days. Also, if a signal occurs after the failure, this is a false positive.
So, in the testing data set, we have 100 false negatives, 273 false positives, 108,497	 true negatives, and 49 true positives. These metrics incorporate the failure window and should give a more realistic view of how the model will perform in production.
Is this good? I still honestly have no idea. To fully understand if the model is good, we must examine it in the context of the problem. We need to evaluate the model relative to the current costs and how much a model will lower these costs.
